{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "papago_backtranslation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uj9glgRQ3aj"
      },
      "outputs": [],
      "source": [
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')        # Head-less 설정\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "driver = webdriver.Chrome('chromedriver', options=options)"
      ],
      "metadata": {
        "id": "OZN1s-3qQ7tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crawling\n",
        "import time\n",
        "import selenium\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from tqdm import tqdm\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "\n",
        "def kor_to_trans(text_data, trans_lang,start_index,final_index):\n",
        "\n",
        "  target_present = EC.presence_of_element_located((By.XPATH, '//*[@id=\"txtTarget\"]'))\n",
        "\n",
        "  for i in tqdm(range(start_index,final_index)): \n",
        "    \n",
        "    if (i!=0)&(i%99==0):\n",
        "      time.sleep(2)\n",
        "      print('{}th : '.format(i), backtrans)\n",
        "      np.save(data_path+'kor_to_eng_train_{}_{}.npy'.format(start_index,final_index),trans_list)\n",
        "    \n",
        "    try:\n",
        "      driver.get('https://papago.naver.com/?sk=ko&tk='+trans_lang+'&st='+text_data[i])\n",
        "      time.sleep(1.5)\n",
        "      element=WebDriverWait(driver, 10).until(target_present)\n",
        "      time.sleep(0.1)\n",
        "      backtrans = element.text \n",
        "\n",
        "      if (backtrans=='')|(backtrans==' '):\n",
        "        element=WebDriverWait(driver, 10).until(target_present)\n",
        "        backtrans = element.text \n",
        "        trans_list.append(backtrans)\n",
        "      else:\n",
        "        trans_list.append(backtrans)\n",
        "    \n",
        "    except:\n",
        "      trans_list.append('')"
      ],
      "metadata": {
        "id": "8PvvCX4sQ9m4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "data_path = \"/content/drive/MyDrive/한국어 문장 관계 분류 경진대회/CSV_files\"\n",
        "\n",
        "# trans_list=[]\n",
        "# kor_to_trans(k['premise'], 'en',0,1000)\n",
        "# np.save(data_path+'kor_to_eng_premise_0_1000.npy',trans_list)\n",
        "\n",
        "\n",
        "# trans_list=[]\n",
        "# kor_to_trans(k['premise'], 'en',10000,20000)\n",
        "# np.save(data_path+'kor_to_eng_premise_10000_20000.npy',trans_list)\n",
        "\n",
        "\n",
        "# trans_list=[]\n",
        "# kor_to_trans(k['premise'], 'en',20000,24997)\n",
        "# np.save(data_path+'kor_to_eng_premise_20000_24997.npy',trans_list)\n",
        "\n",
        "# trans_list=[]\n",
        "# kor_to_trans(k['hypothesis'], 'en',0,10000)\n",
        "# np.save(data_path+'kor_to_eng_hypothesis_0_10000.npy',trans_list)\n",
        "\n",
        "\n",
        "# trans_list=[]\n",
        "# kor_to_trans(k['hypothesis'], 'en',10000,20000)\n",
        "# np.save(data_path+'kor_to_eng_hypothesis_10000_20000.npy',trans_list)\n",
        "\n",
        "\n",
        "# trans_list=[]\n",
        "# kor_to_trans(k['hypothesis'], 'en',20000,24997)\n",
        "# np.save(data_path+'kor_to_eng_hypothesis_20000_24997.npy',trans_list)"
      ],
      "metadata": {
        "id": "6ULSxTt2Sf-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "eng_premise0=np.load(data_path+'kor_to_eng_premise_0_1000.npy')\n",
        "eng_premise1=np.load(data_path+'kor_to_eng_premise_0_10000.npy')\n",
        "eng_premise2=np.load(data_path+'kor_to_eng_premise_10000_20000.npy')\n",
        "eng_premise3=np.load(data_path+'kor_to_eng_premise_20000_24997.npy')\n",
        "\n",
        "eng_hypothesis0=np.load(data_path+'kor_to_eng_hypothesis_0_10000.npy')\n",
        "eng_hypothesis1=np.load(data_path+'kor_to_eng_hypothesis_10000_20000.npy')\n",
        "eng_hypothesis2=np.load(data_path+'kor_to_eng_hypothesis_20000_24997.npy')\n",
        "\n",
        "eng_data_premise=[*eng_premise0,*eng_premise1,*eng_premise2, *eng_premise3]\n",
        "eng_data_premise=pd.DataFrame(eng_data_premise,columns=['eng_premise'])\n",
        "\n",
        "eng_data_hypothesis=[*eng_hypothesis0,*eng_hypothesis1,*eng_hypothesis2]\n",
        "eng_data_hypothesis=pd.DataFrame(eng_data_hypothesis,columns=['eng_hypothesis'])"
      ],
      "metadata": {
        "id": "HW1jMsCYSlhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kor_to_trans_again(text_data, trans_lang,start_index,final_index):\n",
        "\n",
        "  target_present = EC.presence_of_element_located((By.XPATH, '//*[@id=\"txtTarget\"]'))\n",
        "\n",
        "  for i in tqdm(range(start_index,final_index)): \n",
        "    \n",
        "    if (i!=0)&(i%99==0):\n",
        "      time.sleep(2)\n",
        "      print('{}th : '.format(i), backtrans)\n",
        "      np.save(data_path+'kr_title.npy',trans_list)\n",
        "    \n",
        "    try:\n",
        "      driver.get('https://papago.naver.com/?sk=ko&tk='+trans_lang+'&st='+text_data[i])\n",
        "      time.sleep(1.5)\n",
        "      element=WebDriverWait(driver, 10).until(target_present)\n",
        "      time.sleep(0.1)\n",
        "      backtrans = element.text \n",
        "\n",
        "      if (backtrans=='')|(backtrans==' '):\n",
        "        element=WebDriverWait(driver, 10).until(target_present)\n",
        "        backtrans = element.text \n",
        "        trans_list.append(backtrans)\n",
        "      else:\n",
        "        trans_list.append(backtrans)\n",
        "    \n",
        "    except:\n",
        "      trans_list.append('')"
      ],
      "metadata": {
        "id": "oK5afJKfSlln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "data_path = \"/content/drive/MyDrive/한국어 문장 관계 분류 경진대회/CSV_files\"\n",
        "\n",
        "trans_list=[]\n",
        "kor_to_trans_again(eng_data_premise_all['eng_premise'], 'ko',0,24997)\n",
        "np.save(data_path+'eng_to_kor_premise_0_24997.npy',trans_list)\n",
        "\n",
        "\n",
        "trans_list=[]\n",
        "kor_to_trans_again(eng_data_hypothesis_all['eng_hypothesis'], 'ko',0,24997)\n",
        "np.save(data_path+'eng_to_kor_hypothesis_0_24997.npy',trans_list)"
      ],
      "metadata": {
        "id": "XoBkwMOvS5Yh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}